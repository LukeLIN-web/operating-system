[TOC]

## Main Memory

- 保护：进程只能access自己地址空间的地址
  - 硬件或软件
  - 简单实现：base + limit
  
- Address Binding
  
  - A compiler typically binds symbolic addresses to reloacatable addresses
  - The linker or loader binds the relocatable addresses to absolute address
  
- 逻辑地址和物理地址

  - 逻辑地址：虚拟地址
  - Logical and physical addresses are the same in compile-time and load-time
    address-binding schemes; logical (virtual) and physical addresses differ in
    execution-time address-binding scheme

- MMU (memory-management unit)

  - **Hardware device** that at **run time** maps virtual to physical address

  - 虚拟地址转化为物理地址

  - 还会做一些保护：权限位的设置（可读可写的设置）

  - 由操作系统管理

  - 最简单的一种实现方式：relocation register

    - relocation寄存器的值作为基地址

      <img src="Main%20Memory.assets/image-20201127133959679.png" alt="image-20201127133959679" style="zoom: 25%;" />

- <img src="Main%20Memory.assets/image-20201127182346789.png" alt="image-20201127182346789" style="zoom:33%;" />

- Dynamic loading

  - 执行时不需要把整个程序放入内存：例程被调用时再加载
  - 例程以relocatable load format保存在disk中
  - Routine is loaded only when it is needed -> Useful when large amounts of code
    are needed to handle infrequently occurring cases
  - 不需要os的特定支持
    - It is the responsibility of the users to design their programs to take
      advantage of such a method. Operating systems may help the programmer,
      however, by providing library routines to implement dynamic loading.

- Dynamic linking

  - **linking** postponed until **execution time**
  - 库可以在多个进程间共享，内存中只会有一份dll实例
  - 需要操作系统的支持
    - If the processes in memory are protected
      from one another, then the operating system is the only entity that can
      check to see whether the needed routine is in another process’s memory space
      or that can allow multiple processes to access the same memory addresses.
      We elaborate on this concept, as well as how DLLs can be shared by multiple

- <img src="Main%20Memory.assets/image-20201127140734214.png" alt="image-20201127140734214" style="zoom:50%;" />

- relocation-register scheme

  <img src="Main%20Memory.assets/image-20201127142127313.png" alt="image-20201127142127313" style="zoom:50%;" />

  - When the CPU scheduler selects a process for execution, the dispatcher
    loads **the relocation and limit registers with the correct values as part of the**
    **context switch.** 
  - Because every address generated by a CPU is checked against
    these registers, we can protect both the operating system and the other users’
    programs and data from being modified by this running process.
  - allow the operating system’s size to change dynamically.

- 内存分配

  - first-fit：第一块足够大的
  - best-fit：足够大的里最小的
  - worst-fit：最大的hole

- Fragmentation

  - External fragmentation
    - 内存空间足够满足一个需要，但是空闲的空间是不连续的
    - 内存分配方式影响碎片数量：First fit is better for some systems, whereas best fit is better
      for others
    - 50-percent rule：
      - Statistical analysis of **first fit**, for instance, reveals that, even with some optimization,
        given N allocated blocks, another 0.5 N blocks will be lost to fragmentation.
        That is, one-third of memory may be unusable! This property is known as the
        50-percent rule.
  - Internal fragmentation
    - 分配给一个进程的内存可能会稍微比它需要的更多
  - 解决external fragmentation
    - compaction
      - 并不是一直可行
        - If **relocation is static and is done at assembly or load time**, compaction cannot be done
        - It is possible only if relocation is dynamic and is done at execution time
        - If addresses are relocated dynamically, relocation requires only moving the program and data and then changing the base register to reflect the new base address.
    - Paging

- 分页：物理地址可以不连续

#### Paging

- 避免了外部碎片化，但还有内部碎片化

- 物理内存中：frames，逻辑地址中：pages

- 需要跟踪所有的free frames

- 需要建立页表，将逻辑地址转为物理地址

- 页号用来在页表中索引，页内偏移

  <img src="Main%20Memory.assets/image-20201127184053782.png" alt="image-20201127184053782" style="zoom: 67%;" />

- <img src="Main%20Memory.assets/image-20201127184152096.png" alt="image-20201127184152096" style="zoom:50%;" />

- Frame Table

  - 管理物理的frame，需要有一个数据结构去追踪当前物理内存哪些frame是空/不空
  - Which frame is free, and how many frames have been allocated
  - the allocated frame belongs to which process
  - One entry for each physical frame

#### Hardware Support

- 页表存在寄存器
  - 缺点：the table size is very small, and the context switchneed to save and restore these registers
- 存在main memory
  - **page-table base register (PTBR)** points to the page table
    - PTBR存的是物理地址
  - **page-table length register (PTLR)** indicates the size of the page table
  - 两次内存访问
    - 第一次查页表，第二次for data / instuction
    - CPU can cache the translation to avoid one memory access **(TLB)**

#### TLB

- translation look-aside buffer

- TLB usually use a fast-lookup hardware cache called **associative memory**

  - 可以并行地查

- TLB is usually small, 64 to 1024 entries

- 避免不需要的TLB的flush操作（清空）

  - 每个进程有自己的页表，进程切换时需压切换页表
  - 进程切换的时候可以清空TLB再载入另一个进程的TLB
  - 为了不清空，可以在TLB加一个ASID的field，指明是哪一个进程的
    - address-space identifier
  - 这样进程切换的时候不需要清空TLB

- 有些TLB entries可以被多个进程共享，从而固定在TLB中

  - e.g., TLB entries for the kernel

- TLB的miss，有的用硬件做（X86），有的OS做（MIPS，处理TLB miss exception）

- 七个箭头：并行地查

  <img src="Main%20Memory.assets/image-20201127200736699.png" alt="image-20201127200736699" style="zoom: 50%;" />

- EAT：Effective Access Time

#### Memory Protection

- 传统上：以页做保护
- Each page table entry has a present (aka. valid) bit
  - present: the page has a valid physical frame, thus can be accessed
- Each page table entry contains some protection bits
  - kernel/user, read/write, execution?, kernel-execution?
- Any violations of memory protection result in a trap to the kernel

#### Page Sharing

- 共享的是libc的**code**，但是global data不共享
  - global data对应每个进程的global state
- double mapping：多个映射指向同一个物理地址
  - 不同步的问题（不同的进程的权限可能不同）
- <img src="Main%20Memory.assets/image-20201127203118669.png" alt="image-20201127203118669" style="zoom: 50%;" />

#### Structure of page table

- **内存计算**

  <img src="Main%20Memory.assets/image-20201127203714862.png" alt="image-20201127203714862" style="zoom:50%;" />

- 只有一级：内存太大
  - 页表需要**物理地址是连续的**
  - 且每个进程都需要自己的页表

#### Hierarchical page table

- 可以避免物理地址一定要是连续的

- 例如，64位的地址空间，page size为4KB ($2^{12}$)，每个entey是4字节

  - 不分层，则$2^{52}$个entry

  - 2-level，inner page tables可以恰只有一个页的大小（包含$2^{10}$个4-byte的entry）

    - outer page table有$2^{42}$个entry，即$2^{44}$bytes

    <img src="Main%20Memory.assets/image-20201127212451889.png" alt="image-20201127212451889" style="zoom:50%;" />

  - 3-level：最外层page table还是有$2^{34}$bytes（16GB）

    <img src="Main%20Memory.assets/image-20201127212618676.png" alt="image-20201127212618676" style="zoom:50%;" />

  - 4-level比较合适，不过通常不会用完64字节所有的虚拟地址空间

    - 48-bit

  - 

- 用4K的页大小，一个页目录和一个页表都刚好能存在一个页里面

#### Hashed Page Tables

- 此时引用的内存是非连续的，其散布在整个地址空间中

- <img src="Main%20Memory.assets/image-20201127212752999.png" alt="image-20201127212752999" style="zoom:50%;" />

#### Inverted Page Table

- has one entry for each real page (or frame) of memory
- Each entry consists of the virtual address of the page stored in that real memory location, with information about the process that owns the page
- <img src="Main%20Memory.assets/image-20201127213510165.png" alt="image-20201127213510165" style="zoom: 50%;" />
- Each inverted page-table entry is a pair <process-id, page-number> where the
  process-id assumes the role of the address-space identifier. When a memory
  reference occurs, part of the virtual address, consisting of <process-id, pagenumber>,
  is presented to the memory subsystem. The inverted page table
  is then searched for a match. If a match is found—say, at entry i—then the
  physical address <i, offset> is generated. If no match is found, then an illegal
  address access has been attempted.
- 固定了页表的大小：每个物理frame有一个entry
- 增加了在分页引用时的搜索时间
- 共享内存不适用：无法将相同的物理地址映射到多个虚拟地址

#### Swapping

- 物理内存比较小，但是系统里run了很多的process，不够用
- 把一些进程的页先写到硬盘，临时地被交换出去
- context switch也会增加额外的开销：当下一个进程在硬盘里
- 粒度：进程或页
- 现代系统一般不用
  - 大部分PCs和servers的os支持swapping
  - 移动系统一般不支持
  - Mobile devices generally use flash memory rather than more spacious hard disks for nonvolatile storage.
  - flash memory和cpu之间的带宽是比较低的
  - 解决：系统可以kill掉进程

#### Example: The Intel 32 and 64-bit Architectures

- 分段的历史原因
  - 原本的CPU一般是8或16位，最多64K
  - 可以把总线扩充，或用分段
  - 32位里为了兼容还保留，64位基本bypass

#### Example: The Intel IA-32 Architecture

- 通用寄存器：用于ALU运算
  - EAX, EBX, ECX, ...
- 六个段寄存器：用在分段机制
- 控制寄存器
  - EIP(PC)
  - EFLAGS：记录指令执行时候一些状态（有没有溢出）
- CR3寄存器：最顶层的页表的物理地址
- 段描述符：存在段描述符表里的一个entry
- 段描述符表存在什么地方
  - GDTR和LGTR
  - 段分不同的类型：G和L
- 首先需要拿到一个段选择子，用段选择子的某一个数在表里查
- 然后拿到段描述符，段描述符里存的是从逻辑地址到线性地址的base address等一些信息
- 从逻辑地址到线性地址
  - 段选择子：CS, DS这些段寄存器里存的东西
  - 首先要找到段选择子（从段寄存器里找到，根据指令的性质确定使用哪一个段寄存器）
  - 根据段寄存器的内容，再加上表的基地址，找到段描述符
    - 表的基地址在G(L)DTR
  - 在分段的时候就可以做access control

- PAE
  - Physical address extension
  - 在32位的地址空间里，我要能够access大于32位的物理地址
  - 为什么能够access更多的地址？
    - 因为每一个entry都是8个字节的

#### x86

- Linux内核如何设置

  - Setup Segment Registers
    - 设置这个线程里面的ds, es, ss, cs
    - 内核代码，查第12个entry
    - 内核数据，查第13个entry
    - user ...
  - 切换页目录：load_cr3
    - 页目录的地址load到cr3里
    - 切换到一个新进程时用到（不同进程的页表不同）

- Kernel module

  - 关心的寄存器：cr3
  - 专门的指令取gdtr里的值

- 用户态的代码

  <img src="Main%20Memory.assets/image-20201128114737372.png" alt="image-20201128114737372" style="zoom:50%;" />

  - tmp是逻辑地址
  - 根据逻辑地址逐步推出物理地址里存的是不是0x12345678

  <img src="Main%20Memory.assets/image-20201128114903678.png" alt="image-20201128114903678" style="zoom:50%;" />

  - 把cr4 dump出来的目的：需要获得是否enable PAE
  - gdt：global descriptor table
  - pgd：page table dir
  - pt：page table

  <img src="Main%20Memory.assets/image-20201128115409898.png" alt="image-20201128115409898" style="zoom:50%;" />

  - 访问的是user的数据：第15个entry
  - 78
  - 得到段描述符
  - 之后就可以得到段描述符所指定的base address和limitation（表示段的长度有多长）
  - 关心base address：线性地址 = 基地址 + 逻辑地址

  <img src="Main%20Memory.assets/image-20201128115731969.png" alt="image-20201128115731969" style="zoom:50%;" />

  - 线性到物理地址：需要查页表

  <img src="Main%20Memory.assets/image-20201128115915788.png" alt="image-20201128115915788" style="zoom:50%;" />

  - PAE已经打开了
  - 需要看pdpte2的格式
  - 每个entry 8个字节



## Virtual Memory

- 内容
  - demand paging：按需要做页的加载
  - 页替换的算法
  - 访问到一个还没有加载到物理内存时，exception如何处理
  - 抖动
  - x86和riscv

#### Demand Paging

- code共享，global data不共享

- Demand paging brings a page into memory **only when it is accessed**
  - if page is invalid ➠ **abort the operation**（比如栈和堆之间的空白，访问到未分配的内存）
  - if page is valid but not in memory ➠ bring it to memory via swapping
- 用的时候，缺页了再分配physical frame，再加载page
- 实现部分加载programe，按需加载

##### Valid-Invalid Bit

- Each page table entry has a valid–invalid (present) bit
  - V ➠ in memory (memory is resident), I ➠ not-in-memory
  - during address translation, if the entry is invalid, it will trigger a page fault

##### Page Fault

- 内核会maintain每个进程它的虚拟地址空间的分配情况

  - 最常用的是mmap()

- Operating system looks at memory mapping to decide:

  - 访问了不应该touch的虚拟地址

    - 如果注册了信号，则不用kill掉
    - invalid reference ➠ deliver an exception to the process

  - valid but not in memory ➠ swap in

    - get an empty physical frame
    - swap page into frame via disk operation
    - set page table entry to indicate the page is now in memory
    - **restart the instruction that caused the page fault**

    <img src="Main%20Memory.assets/image-20201205133925802.png" alt="image-20201205133925802" style="zoom:50%;" />

  - pure demand paging

    - 从第一条指令开始就缺页

- demand paging需要的硬件支持

  - page table entries with valid / invalid bit
  - backing storage (usually disks)
  - instruction restart

- 有一些硬件的restart不太行

  - 块移动的指令：有部分重叠
  - 当操作部分完成时发生缺页

##### Free-Frame List

- 维护哪些frame是空的

##### Stages in Demand Paging – Worse Case

- 1. Trap to the operating system
  2. Save the user registers and process state
  3. Determine that the interrupt was a page fault
  4. **Check that the page reference was legal and determine the location of the page on the disk**
  5. Issue a read from the disk to a free frame:
  	5.1 Wait in a queue for this device until the read request is serviced
  	5.2 Wait for the device seek and/or latency time
  	5.3 Begin the transfer of the page to a free frame
  6. **While waiting, allocate the CPU to some other user**
  7. Receive an interrupt from the disk I/O subsystem (I/O completed)
  8. Save the registers and process state for the other user
  9. Determine that the interrupt was from the disk
  10. **Correct the page table and other tables to show page is now in memory**
  11. Wait for the CPU to be allocated to this process again
  12. Restore the user registers, process state, and new page table, and then resume the interrupted instruction
- 注意点
  - 知道是page fault后并不always要给它分配physical frame，首先要看page reference是否legal
  - 如果5中没有free frame，则需要页替换

##### Effective Access Time (EAT)

- (1 – p) x memory access + p x (
  	page fault overhead +
    	swap page out + swap page in +
    	instruction restart overhead)

##### Demand Paging Optimizations

- **Swap space** I/O faster than file system I/O even if on the same
  device
  - swap分区：文件系统需要maintain很多metadata，读写data 的时候会读写很多东西，swap分区的metadata少一点，读起来比较快
  - Swap allocated in larger chunks, less management needed than file system
- Copy entire process image to swap space at process load time
  - Then page in and out of swap space

##### Copy-on-Write

- fork()

- 创建子进程：页表肯定要拷贝一份的，物理内存不需要拷贝

- vfork()：假设子进程一定会exec

  - 危险，省内存
  - 不用COW机制

- COW是需要硬件支撑的

  - 需要知道一个page能不能被读写
  - 一旦采用COW，page C就变成只读的
  - 修改它之后，会引发异常，再拷贝一份

  <img src="Main%20Memory.assets/image-20201205143917968.png" alt="image-20201205143917968" style="zoom:50%;" />

#### Page replacement

- 不能把最常用的页换出去
- 避免抖动
- dirty bit：如果page没有修改过，直接discard掉

<img src="Main%20Memory.assets/image-20201205144540629.png" alt="image-20201205144540629" style="zoom:50%;" />

##### Page Replacement Algorithms

- 评估算法：缺页的次数

- reference string：要访问哪些物理的frame

- 一般来说，frame的数量越多，缺页次数越少

  - 但有些算法不一定

- FIFO

  <img src="Main%20Memory.assets/image-20201205145008846.png" alt="image-20201205145008846" style="zoom:50%;" />

  - 15次缺页

  - 有可能frame越多缺页更多

    - **Belady’s Anomaly**
    - 恰巧刚替换出去的马上就要访问

    <img src="Main%20Memory.assets/image-20201205145120716.png" alt="image-20201205145120716" style="zoom:50%;" />

- 如果可以预知未来：

  - Optimal : **replace page that will not be used for the longest time**
  - OPT

- 用以前的信息去近似

  - LRU: Least Recently Used

  - **OPT和LRU不会有Belady’s Anomaly**

  - 实现：counter或stack，比较难用

  - LRU近似：when page is referenced, set the bit to 1 (done by the hardware)

    - 替换reference bit为0的page

  - Additional-Reference-Bits Algorithm

    <img src="Main%20Memory.assets/image-20201205145940566.png" alt="image-20201205145940566" style="zoom:50%;" />

  - Second-chance

    <img src="Main%20Memory.assets/image-20201205150226814.png" alt="image-20201205150226814" style="zoom:50%;" />

    <img src="Main%20Memory.assets/image-20201205150245125.png" alt="image-20201205150245125" style="zoom:50%;" />

  - Enhanced Second-Chance Algorithm

    - (reference, modify)
    - 再看看ppt

- Page-Buffering Algorithms

  - **Keep a pool of free frames, always**
    - **Then frame available when needed**, not found at fault time
    - Read page into free frames without waiting for victims to write out
    - When convenient, evict victim（逐出）

##### Fixed Allocation

##### Global vs. Local Allocation

- Global replacement：一般用全局的
  - 所有的页做统筹
- Local replacement

##### Reclaiming Pages

- 当可用的page比较少时就开始页替换
- 做法
  - kill进程

##### Major and minor page faults

- Major: page is referenced but not in memory
  - 基本不出现
- Minor: mapping does not exist, but the page is in memory
  - Shared library
  - Reclaimed and not freed yet

#### Thrashing

- 如果一个进程得到的页不够，那么缺页率就会上升
  - 得到新页，需要页替换，但替换掉的页可能马上又需要换回来
- 从而导致：
  - 低CPU的利用率（因为持续换入换出，在handler上耗费很多时间）
  - 内核会认为需要increase the degree of multiprogramming to maximize CPU utilization
  - 从而将新的进程加入至系统，加剧这个情况
- **Thrashing: a process is busy swapping pages in and out**
- 抖动发生的原因
  - total size of locality > total memory size
  - 从而导致持续的换入换出
- <img src="Main%20Memory.assets/image-20201205202101688.png" alt="image-20201205202101688" style="zoom:50%;" />

##### Option 1

- Limit thrashing effects by **using local or priority page replacement**
  - One process starts thrashing does not affect others
  - So it cannot cause other processes thrashing

##### Option 2

- Provide a process with as many frames as it needs
- 两个隐含条件
  - 系统的内存大小够大
  - 大概计算出来进程需要多少page
- 假设我们给一个进程分配了足够的帧来满足其当前的局部，然后该进程会产生分页错误来从局部获取分页，直到所有的分页都被加载到内存中。在其再次变动局部前不会产生分页错误。**如果没有为当前的局部分配足够的帧，由于无法将所有使用的分页加载到内存中，因此该进程会发生抖动。**

##### Working-Set Model

- <img src="Main%20Memory.assets/image-20201205203537861.png" alt="image-20201205203537861" style="zoom:50%;" />
- Δ：工作集窗口，用于检查最近引用的Δ个分页
- 工作集 = 最近引用的Δ个分页集
- process i needs WSSi frames
- ...



#### Kernel Memory Allocation

- 有些os可以静态分配好内存，但是比较复杂的（如Linux）还是需要动态内存分配的机制
- 内核可以控制物理地址连续
  - 为什么需要？DMA做内存搬运的时候，物理地址连续就可以直接搬运

##### Buddy System

- 预先分配一个比较大的chunk
- <img src="Main%20Memory.assets/image-20201205210135086.png" alt="image-20201205210135086" style="zoom:50%;" />
  - 注意：256KB的chunk物理地址是连续的
  - 很容易做聚合
  - disadvantage: internal fragmentation
    - 33k request -> 64k segment

##### Slab Allocator

- 把经常使用的object预先分配成不同大小的cache，这些cache最后形成slab



#### Other Considerations

##### Prepaging

- 预分配一些page
- 预分配的page可能不会用到

##### Page Size

##### TLB Reach

- TLB reach: the amount of memory accessible from the TLB
- Increase the page size to reduce TLB pressure

##### Program Structure

##### I/O interlock



#### Linux virtual memory

<img src="Main%20Memory.assets/image-20201209182153284.png" alt="image-20201209182153284" style="zoom: 33%;" />

- kmalloc, vmalloc
  - 内核里面的API
  - vmalloc：虚拟地址连续，不保证物理地址连续
  - kmalloc：**保证物理地址连续**

<img src="Main%20Memory.assets/image-20201209183050010.png" alt="image-20201209183050010" style="zoom:50%;" />

- 书上说slab没有内部碎片：描述有点问题
  - 实际上还是做了一点round-up
- DMA使用的内存需要物理连续
  - 操作的是物理地址，脱离CPU操作物理内存
- 内核虚拟地址空间
  - 内核逻辑地址：固定的映射关系，差一个offset
    - 虚拟地址连续，物理地址也连续
- 有的时候内核是需要往User space的栈上去写东西
  - 在信号处理里面用到
- slab
  - 在物理页的基础，对一些kernel object做cache
  - 一次预分配比如32K的一段连续的物理地址空间
  - 在里面做比如说50个kernel object的cache
  - 下次要分配一个kernel object的时候直接从slab里面拿就好

#### Dirty COW Attack

- mmap()

  <img src="Main%20Memory.assets/image-20201212122913235.png" alt="image-20201212122913235" style="zoom:50%;" />

  - 把一个file map到memory里面去
  - 以后对一个file的操作，可以直接对memory操作
  - 这样性能会好：原来操作文件需要先open得到文件描述符，而后在通过read()和write()读写，这两个都是system call
    - 而mmap，直接对memory操作
    - 何时sink到真正的文件里面？操作系统阶段性会去做，不用管
  - fd：文件在用户态程序的代理人，内核通过代理人找到真正要操作的文件
    - 真正对文件的操作是内核处理的

- madvise

  - 告诉内核对某一个虚拟地址空间会怎么用
  - 会做一些优化的策略

  















